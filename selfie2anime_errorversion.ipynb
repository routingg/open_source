{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/routingg/open_source/blob/master/selfie2anime_errorversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JyNOzXg8RXX"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWlApOfk7qbo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WGGYJQg9NAW"
      },
      "source": [
        "**Custom Dataset** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "56a7MLt08O2t"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, img_dir):\n",
        "        img_dir = BASE_DATASET_PATH + \"/\" + img_dir + \"/\"\n",
        "        \n",
        "        path_list = os.listdir(img_dir)\n",
        "        abspath = os.path.abspath(img_dir) \n",
        "        \n",
        "        self.img_dir = img_dir\n",
        "        self.img_list = [os.path.join(abspath, path) for path in path_list]\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(IMG_SIZE),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]), # normalize image between -1 and 1\n",
        "        ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.img_list[idx]\n",
        "        img = Image.open(path).convert('RGB')\n",
        "\n",
        "        img_tensor = self.transform(img)\n",
        "        return img_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZwczjOs9jzm"
      },
      "source": [
        "**Discriminator Class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nON0Tf7B8O67"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,conv_dim=32):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, conv_dim, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(conv_dim, conv_dim*2, 4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim*2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(conv_dim*2, conv_dim*4, 4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim*4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(conv_dim*4, conv_dim*8, 4, padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim*8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(conv_dim*8, 1, 4, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.main(x)\n",
        "        x = F.avg_pool2d(x, x.size()[2:])\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KG6O0eL9-v9"
      },
      "source": [
        "**ResidualBlock Class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9YA0aKtW8O-Z"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_channels, in_channels, 3),\n",
        "            nn.InstanceNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_channels, in_channels, 3),\n",
        "            nn.InstanceNorm2d(in_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.main(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI4EH1pt-CwL"
      },
      "source": [
        "**Generator Class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3MjPgjM28PCB"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, conv_dim=64, n_res_block=9):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(3, conv_dim, 7),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(conv_dim, conv_dim*2, 3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim*2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(conv_dim*2, conv_dim*4, 3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim*4),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            \n",
        "            nn.ConvTranspose2d(conv_dim*4, conv_dim*2, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim*2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(conv_dim*2, conv_dim, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(conv_dim, 3, 7),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR9MPBDd-8jk"
      },
      "source": [
        "**CycleGAN Class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KeDKXANF-8vc"
      },
      "outputs": [],
      "source": [
        "class CycleGAN:\n",
        "\n",
        "    def __init__(self, g_conv_dim=64, d_conv_dim=64, n_res_block=6):\n",
        "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "        self.G_XtoY = Generator(conv_dim=g_conv_dim, n_res_block=n_res_block).to(self.device)\n",
        "        self.G_YtoX = Generator(conv_dim=g_conv_dim, n_res_block=n_res_block).to(self.device)\n",
        "\n",
        "        self.D_X = Discriminator(conv_dim=d_conv_dim).to(self.device)\n",
        "        self.D_Y = Discriminator(conv_dim=d_conv_dim).to(self.device)\n",
        "\n",
        "        print(f\"Models running of {self.device}\")\n",
        "\n",
        "    def load_model(self, filename):\n",
        "        save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n",
        "        return torch.load(save_filename)\n",
        "\n",
        "    def real_mse_loss(self, D_out):\n",
        "        return torch.mean((D_out-1)**2)\n",
        "\n",
        "\n",
        "    def fake_mse_loss(self, D_out):\n",
        "        return torch.mean(D_out**2)\n",
        "\n",
        "\n",
        "    def cycle_consistency_loss(self, real_img, reconstructed_img, lambda_weight):\n",
        "        reconstr_loss = torch.mean(torch.abs(real_img - reconstructed_img))\n",
        "        return lambda_weight*reconstr_loss\n",
        "    \n",
        "    def train_generator(self, optimizers, images_x, images_y):\n",
        "        # Generator YtoX\n",
        "        optimizers[\"g_optim\"].zero_grad()\n",
        "\n",
        "        fake_images_x = self.G_YtoX(images_y)\n",
        "\n",
        "        d_real_x = self.D_X(fake_images_x)\n",
        "        g_YtoX_loss = self.real_mse_loss(d_real_x)\n",
        "\n",
        "        recon_y = self.G_XtoY(fake_images_x)\n",
        "        recon_y_loss = self.cycle_consistency_loss(images_y, recon_y, lambda_weight=10)\n",
        "\n",
        "\n",
        "        # Generator XtoY\n",
        "        fake_images_y = self.G_XtoY(images_x)\n",
        "\n",
        "        d_real_y = self.D_Y(fake_images_y)\n",
        "        g_XtoY_loss = self.real_mse_loss(d_real_y)\n",
        "\n",
        "        recon_x = self.G_YtoX(fake_images_y)\n",
        "        recon_x_loss = self.cycle_consistency_loss(images_x, recon_x, lambda_weight=10)\n",
        "\n",
        "        g_total_loss = g_YtoX_loss + g_XtoY_loss + recon_y_loss + recon_x_loss\n",
        "        g_total_loss.backward()\n",
        "        optimizers[\"g_optim\"].step()\n",
        "\n",
        "        return g_total_loss.item()\n",
        "\n",
        "    \n",
        "    def train_discriminator(self, optimizers, images_x, images_y):\n",
        "        # Discriminator x\n",
        "        optimizers[\"d_x_optim\"].zero_grad()\n",
        "\n",
        "        d_real_x = self.D_X(images_x)\n",
        "        d_real_loss_x = self.real_mse_loss(d_real_x)\n",
        "        \n",
        "        fake_images_x = self.G_YtoX(images_y)\n",
        "\n",
        "        d_fake_x = self.D_X(fake_images_x)\n",
        "        d_fake_loss_x = self.fake_mse_loss(d_fake_x)\n",
        "        \n",
        "        d_x_loss = d_real_loss_x + d_fake_loss_x\n",
        "        d_x_loss.backward()\n",
        "        optimizers[\"d_x_optim\"].step()\n",
        "\n",
        "\n",
        "        # Discriminator y\n",
        "        optimizers[\"d_y_optim\"].zero_grad()            \n",
        "        d_real_y = self.D_Y(images_y)\n",
        "        d_real_loss_x = self.real_mse_loss(d_real_y)\n",
        "    \n",
        "        fake_images_y = self.G_XtoY(images_x)\n",
        "\n",
        "        d_fake_y = self.D_Y(fake_images_y)\n",
        "        d_fake_loss_y = self.fake_mse_loss(d_fake_y)\n",
        "\n",
        "        d_y_loss = d_real_loss_x + d_fake_loss_y\n",
        "        d_y_loss.backward()\n",
        "        optimizers[\"d_y_optim\"].step()\n",
        "\n",
        "        return d_x_loss.item(), d_y_loss.item()\n",
        "\n",
        "\n",
        "    def train(self, optimizers, data_loader_x, data_loader_y, print_every=10, sample_every=100):\n",
        "        losses = []\n",
        "        g_total_loss_min = np.Inf\n",
        "    \n",
        "        fixed_x = next(iter(data_loader_x))[1].to(self.device)\n",
        "        fixed_y = next(iter(data_loader_y))[1].to(self.device)\n",
        "\n",
        "        print(f'Running on {self.device}')\n",
        "        for epoch in range(EPOCHS):\n",
        "            for (images_x, images_y) in zip(data_loader_x, data_loader_y):\n",
        "                images_x, images_y = images_x.to(self.device), images_y.to(self.device)\n",
        "                \n",
        "                g_total_loss = self.train_generator(optimizers, images_x, images_y)\n",
        "                d_x_loss, d_y_loss = self.train_discriminator(optimizers, images_x, images_y)\n",
        "                \n",
        "            \n",
        "            if epoch % print_every == 0:\n",
        "                losses.append((d_x_loss, d_y_loss, g_total_loss))\n",
        "                print('Epoch [{:5d}/{:5d}] | d_X_loss: {:6.4f} | d_Y_loss: {:6.4f} | g_total_loss: {:6.4f}'\n",
        "                .format(\n",
        "                    epoch, \n",
        "                    EPOCHS, \n",
        "                    d_x_loss, \n",
        "                    d_y_loss, \n",
        "                    g_total_loss\n",
        "                ))\n",
        "                \n",
        "            if g_total_loss < g_total_loss_min:\n",
        "                g_total_loss_min = g_total_loss\n",
        "                \n",
        "                torch.save(self.G_XtoY.state_dict(), \"G_X2Y\")\n",
        "                torch.save(self.G_YtoX.state_dict(), \"G_Y2X\")\n",
        "                                \n",
        "                torch.save(self.D_X.state_dict(), \"D_X\")\n",
        "                torch.save(self.D_Y.state_dict(), \"D_Y\")\n",
        "                \n",
        "                print(\"Models Saved\")\n",
        "                \n",
        "                \n",
        "\n",
        "        return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw7sh2GZ_mLJ"
      },
      "source": [
        "**Config**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vm28yN6k_mXT"
      },
      "outputs": [],
      "source": [
        "BASE_DATASET_PATH = '/content/drive/MyDrive/selfie2anime'\n",
        "X_DATASET = \"trainA\"\n",
        "Y_DATASET = \"trainB\"\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "N_WORKERS = 0\n",
        "\n",
        "IMG_SIZE = 128\n",
        "LR = 0.0002\n",
        "BETA1 = 0.5\n",
        "BETA2 = 0.999\n",
        "\n",
        "EPOCHS = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPTUDgN_reA"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1sZtI6-_rqJ",
        "outputId": "8013e3b5-4284-4a4e-f420-56098d411c41"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models running of cuda\n",
            "Running on cuda\n"
          ]
        }
      ],
      "source": [
        "# Dataset\n",
        "x_dataset = Dataset(X_DATASET)\n",
        "y_dataset = Dataset(Y_DATASET)\n",
        "\n",
        "data_loader_x = DataLoader(x_dataset, BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
        "data_loader_y = DataLoader(y_dataset, BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
        "\n",
        "# Model\n",
        "cycleGan = CycleGAN()\n",
        "\n",
        "# Oprimizer\n",
        "g_params = list(cycleGan.G_XtoY.parameters()) + list(cycleGan.G_YtoX.parameters())\n",
        "\n",
        "optimizers = {\n",
        "    \"g_optim\": optim.Adam(g_params, LR, [BETA1, BETA2]),\n",
        "    \"d_x_optim\": optim.Adam(cycleGan.D_X.parameters(), LR, [BETA1, BETA2]),\n",
        "    \"d_y_optim\": optim.Adam(cycleGan.D_Y.parameters(), LR, [BETA1, BETA2])\n",
        "}\n",
        "\n",
        "# Train\n",
        "losses = cycleGan.train(optimizers, data_loader_x, data_loader_y, print_every=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9PDtvfDhTQ_"
      },
      "outputs": [],
      "source": [
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "losses = np.array(losses)\n",
        "plt.plot(losses.T[0], label='Discriminator, X', alpha=0.5)\n",
        "plt.plot(losses.T[1], label='Discriminator, Y', alpha=0.5)\n",
        "plt.plot(losses.T[2], label='Generators', alpha=0.5)\n",
        "plt.title(\"Training Losses\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28F2k44uhV0z"
      },
      "outputs": [],
      "source": [
        "# Test Dataset\n",
        "# x_dataset = Dataset(\"testA\")\n",
        "# y_dataset = Dataset(\"testB\")\n",
        "\n",
        "# data_loader_x = DataLoader(x_dataset, BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
        "# data_loader_y = DataLoader(y_dataset, BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
        "\n",
        "# samples = []\n",
        "\n",
        "# for i in range(12):\n",
        "#     fixed_x = next(iter(data_loader_x))[i].to(cycleGan.device)\n",
        "#     fake_y = cycleGan.G_XtoY(torch.unsqueeze(fixed_x, dim=0))\n",
        "#     samples.extend([fixed_x, torch.squeeze(fake_y, 0)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3j3HTCrcMdRt"
      },
      "outputs": [],
      "source": [
        "# Test Dataset\n",
        "x_dataset = Dataset(\"testA\")\n",
        "y_dataset = Dataset(\"testB\")\n",
        "\n",
        "data_loader_x = DataLoader(x_dataset, BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
        "data_loader_y = DataLoader(y_dataset, BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
        "\n",
        "samples = []\n",
        "\n",
        "for i in range(12):\n",
        "    fixed_x = next(iter(data_loader_x))[i].to(cycleGan.device)\n",
        "    \n",
        "    # 크기가 다른 텐서의 차원을 맞추기\n",
        "    fixed_x = fixed_x[:, :, :, :128]  # 예시로 128로 크기 조정\n",
        "    \n",
        "    fake_y = cycleGan.G_XtoY(torch.unsqueeze(fixed_x, dim=0))\n",
        "    \n",
        "    # 크기가 다른 텐서의 차원을 맞추기\n",
        "    fake_y = fake_y[:, :, :, :128]  # 예시로 128로 크기 조정\n",
        "    \n",
        "    samples.extend([fixed_x, torch.squeeze(fake_y, 0)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xusSils_hZXz"
      },
      "source": [
        "**Test Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQ2VglAShV7_"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(18, 14))\n",
        "grid = ImageGrid(fig, 111, nrows_ncols=(5, 4), axes_pad=0.5)\n",
        "\n",
        "\n",
        "for i, (ax, im) in enumerate(zip(grid, samples)):\n",
        "    _, w, h = im.size()\n",
        "    im = im.detach().cpu().numpy()\n",
        "    im = np.transpose(im, (1, 2, 0))\n",
        "    \n",
        "    im = ((im +1)*255 / (2)).astype(np.uint8)\n",
        "    ax.imshow(im.reshape((w,h,3)))\n",
        "\n",
        "    ax.xaxis.set_visible(False)\n",
        "    ax.yaxis.set_visible(False)\n",
        "\n",
        "    if i%2 == 0: title = \"selfie\"\n",
        "    else: title = \"anime\"\n",
        "\n",
        "    ax.set_title(title)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XckTQLRuhV-b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1xBaVx71JNBPKJxoYd2LKMbzfiEg5XyT-",
      "authorship_tag": "ABX9TyOc/Tl5bjm3SPzci21Yc3OR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}