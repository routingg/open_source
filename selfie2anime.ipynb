{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPa+1lxGFJOg3iSDN0MvzpY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/routingg/open_source/blob/master/selfie2anime.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "_JyNOzXg8RXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WWlApOfk7qbo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Dataset** "
      ],
      "metadata": {
        "id": "6WGGYJQg9NAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, img_dir):\n",
        "        img_dir = BASE_DATASET_PATH + \"/\" + img_dir + \"/\"\n",
        "        \n",
        "        path_list = os.listdir(img_dir)\n",
        "        abspath = os.path.abspath(img_dir) \n",
        "        \n",
        "        self.img_dir = img_dir\n",
        "        self.img_list = [os.path.join(abspath, path) for path in path_list]\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(IMG_SIZE),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]), # normalize image between -1 and 1\n",
        "        ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.img_list[idx]\n",
        "        img = Image.open(path).convert('RGB')\n",
        "\n",
        "        img_tensor = self.transform(img)\n",
        "        return img_tensor"
      ],
      "metadata": {
        "id": "56a7MLt08O2t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discriminator Class**"
      ],
      "metadata": {
        "id": "jZwczjOs9jzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,conv_dim=32):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, conv_dim, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(conv_dim, conv_dim*2, 4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim*2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(conv_dim*2, conv_dim*4, 4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim*4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(conv_dim*4, conv_dim*8, 4, padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim*8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(conv_dim*8, 1, 4, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.main(x)\n",
        "        x = F.avg_pool2d(x, x.size()[2:])\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "nON0Tf7B8O67"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResidualBlock Class**"
      ],
      "metadata": {
        "id": "2KG6O0eL9-v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_channels, in_channels, 3),\n",
        "            nn.InstanceNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_channels, in_channels, 3),\n",
        "            nn.InstanceNorm2d(in_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.main(x)"
      ],
      "metadata": {
        "id": "9YA0aKtW8O-Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generator Class**"
      ],
      "metadata": {
        "id": "hI4EH1pt-CwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, conv_dim=64, n_res_block=9):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(3, conv_dim, 7),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(conv_dim, conv_dim*2, 3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim*2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(conv_dim*2, conv_dim*4, 3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim*4),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            ResidualBlock(conv_dim*4),\n",
        "            \n",
        "            nn.ConvTranspose2d(conv_dim*4, conv_dim*2, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim*2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(conv_dim*2, conv_dim, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(conv_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(conv_dim, 3, 7),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ],
      "metadata": {
        "id": "3MjPgjM28PCB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CycleGAN Class**"
      ],
      "metadata": {
        "id": "gR9MPBDd-8jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleGAN:\n",
        "\n",
        "    def __init__(self, g_conv_dim=64, d_conv_dim=64, n_res_block=6):\n",
        "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "        self.G_XtoY = Generator(conv_dim=g_conv_dim, n_res_block=n_res_block).to(self.device)\n",
        "        self.G_YtoX = Generator(conv_dim=g_conv_dim, n_res_block=n_res_block).to(self.device)\n",
        "\n",
        "        self.D_X = Discriminator(conv_dim=d_conv_dim).to(self.device)\n",
        "        self.D_Y = Discriminator(conv_dim=d_conv_dim).to(self.device)\n",
        "\n",
        "        print(f\"Models running of {self.device}\")\n",
        "\n",
        "    def load_model(self, filename):\n",
        "        save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n",
        "        return torch.load(save_filename)\n",
        "\n",
        "    def real_mse_loss(self, D_out):\n",
        "        return torch.mean((D_out-1)**2)\n",
        "\n",
        "\n",
        "    def fake_mse_loss(self, D_out):\n",
        "        return torch.mean(D_out**2)\n",
        "\n",
        "\n",
        "    def cycle_consistency_loss(self, real_img, reconstructed_img, lambda_weight):\n",
        "        reconstr_loss = torch.mean(torch.abs(real_img - reconstructed_img))\n",
        "        return lambda_weight*reconstr_loss\n",
        "    \n",
        "    def train_generator(self, optimizers, images_x, images_y):\n",
        "        # Generator YtoX\n",
        "        optimizers[\"g_optim\"].zero_grad()\n",
        "\n",
        "        fake_images_x = self.G_YtoX(images_y)\n",
        "\n",
        "        d_real_x = self.D_X(fake_images_x)\n",
        "        g_YtoX_loss = self.real_mse_loss(d_real_x)\n",
        "\n",
        "        recon_y = self.G_XtoY(fake_images_x)\n",
        "        recon_y_loss = self.cycle_consistency_loss(images_y, recon_y, lambda_weight=10)\n",
        "\n",
        "\n",
        "        # Generator XtoY\n",
        "        fake_images_y = self.G_XtoY(images_x)\n",
        "\n",
        "        d_real_y = self.D_Y(fake_images_y)\n",
        "        g_XtoY_loss = self.real_mse_loss(d_real_y)\n",
        "\n",
        "        recon_x = self.G_YtoX(fake_images_y)\n",
        "        recon_x_loss = self.cycle_consistency_loss(images_x, recon_x, lambda_weight=10)\n",
        "\n",
        "        g_total_loss = g_YtoX_loss + g_XtoY_loss + recon_y_loss + recon_x_loss\n",
        "        g_total_loss.backward()\n",
        "        optimizers[\"g_optim\"].step()\n",
        "\n",
        "        return g_total_loss.item()\n",
        "\n",
        "    \n",
        "    def train_discriminator(self, optimizers, images_x, images_y):\n",
        "        # Discriminator x\n",
        "        optimizers[\"d_x_optim\"].zero_grad()\n",
        "\n",
        "        d_real_x = self.D_X(images_x)\n",
        "        d_real_loss_x = self.real_mse_loss(d_real_x)\n",
        "        \n",
        "        fake_images_x = self.G_YtoX(images_y)\n",
        "\n",
        "        d_fake_x = self.D_X(fake_images_x)\n",
        "        d_fake_loss_x = self.fake_mse_loss(d_fake_x)\n",
        "        \n",
        "        d_x_loss = d_real_loss_x + d_fake_loss_x\n",
        "        d_x_loss.backward()\n",
        "        optimizers[\"d_x_optim\"].step()\n",
        "\n",
        "\n",
        "        # Discriminator y\n",
        "        optimizers[\"d_y_optim\"].zero_grad()            \n",
        "        d_real_y = self.D_Y(images_y)\n",
        "        d_real_loss_x = self.real_mse_loss(d_real_y)\n",
        "    \n",
        "        fake_images_y = self.G_XtoY(images_x)\n",
        "\n",
        "        d_fake_y = self.D_Y(fake_images_y)\n",
        "        d_fake_loss_y = self.fake_mse_loss(d_fake_y)\n",
        "\n",
        "        d_y_loss = d_real_loss_x + d_fake_loss_y\n",
        "        d_y_loss.backward()\n",
        "        optimizers[\"d_y_optim\"].step()\n",
        "\n",
        "        return d_x_loss.item(), d_y_loss.item()\n",
        "\n",
        "\n",
        "    def train(self, optimizers, data_loader_x, data_loader_y, print_every=10, sample_every=100):\n",
        "        losses = []\n",
        "        g_total_loss_min = np.Inf\n",
        "    \n",
        "        fixed_x = next(iter(data_loader_x))[1].to(self.device)\n",
        "        fixed_y = next(iter(data_loader_y))[1].to(self.device)\n",
        "\n",
        "        print(f'Running on {self.device}')\n",
        "        for epoch in range(EPOCHS):\n",
        "            for (images_x, images_y) in zip(data_loader_x, data_loader_y):\n",
        "                images_x, images_y = images_x.to(self.device), images_y.to(self.device)\n",
        "                \n",
        "                g_total_loss = self.train_generator(optimizers, images_x, images_y)\n",
        "                d_x_loss, d_y_loss = self.train_discriminator(optimizers, images_x, images_y)\n",
        "                \n",
        "            \n",
        "            if epoch % print_every == 0:\n",
        "                losses.append((d_x_loss, d_y_loss, g_total_loss))\n",
        "                print('Epoch [{:5d}/{:5d}] | d_X_loss: {:6.4f} | d_Y_loss: {:6.4f} | g_total_loss: {:6.4f}'\n",
        "                .format(\n",
        "                    epoch, \n",
        "                    EPOCHS, \n",
        "                    d_x_loss, \n",
        "                    d_y_loss, \n",
        "                    g_total_loss\n",
        "                ))\n",
        "                \n",
        "            if g_total_loss < g_total_loss_min:\n",
        "                g_total_loss_min = g_total_loss\n",
        "                \n",
        "                torch.save(self.G_XtoY.state_dict(), \"G_X2Y\")\n",
        "                torch.save(self.G_YtoX.state_dict(), \"G_Y2X\")\n",
        "                                \n",
        "                torch.save(self.D_X.state_dict(), \"D_X\")\n",
        "                torch.save(self.D_Y.state_dict(), \"D_Y\")\n",
        "                \n",
        "                print(\"Models Saved\")\n",
        "                \n",
        "                \n",
        "\n",
        "        return losses"
      ],
      "metadata": {
        "id": "KeDKXANF-8vc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Config**"
      ],
      "metadata": {
        "id": "Dw7sh2GZ_mLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DATASET_PATH = \"C:\\selfie2anime\"\n",
        "X_DATASET = \"trainA\"\n",
        "Y_DATASET = \"trainB\"\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "N_WORKERS = 0\n",
        "\n",
        "IMG_SIZE = 128\n",
        "LR = 0.0002\n",
        "BETA1 = 0.5\n",
        "BETA2 = 0.999\n",
        "\n",
        "EPOCHS = 100"
      ],
      "metadata": {
        "id": "Vm28yN6k_mXT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "nVPTUDgN_reA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "x_dataset = Dataset(X_DATASET)\n",
        "y_dataset = Dataset(Y_DATASET)\n",
        "\n",
        "data_loader_x = DataLoader(x_dataset, BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
        "data_loader_y = DataLoader(y_dataset, BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
        "\n",
        "# Model\n",
        "cycleGan = CycleGAN()\n",
        "\n",
        "# Oprimizer\n",
        "g_params = list(cycleGan.G_XtoY.parameters()) + list(cycleGan.G_YtoX.parameters())\n",
        "\n",
        "optimizers = {\n",
        "    \"g_optim\": optim.Adam(g_params, LR, [BETA1, BETA2]),\n",
        "    \"d_x_optim\": optim.Adam(cycleGan.D_X.parameters(), LR, [BETA1, BETA2]),\n",
        "    \"d_y_optim\": optim.Adam(cycleGan.D_Y.parameters(), LR, [BETA1, BETA2])\n",
        "}\n",
        "\n",
        "# Train\n",
        "losses = cycleGan.train(optimizers, data_loader_x, data_loader_y, print_every=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "H1sZtI6-_rqJ",
        "outputId": "98c4b91c-ec87-4088-926c-5996ae6d5448"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-61c798cbf713>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_DATASET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_DATASET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_loader_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_WORKERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-f1605764937f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_dir)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBASE_DATASET_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpath_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mabspath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\selfie2anime/trainA/'"
          ]
        }
      ]
    }
  ]
}